
17-02-2020
    data: https://www.kaggle.com/c/digit-recognizer/data
    anaconda (py interpreter with scipy matplotlib)
        -> installed in /home/paolo/.anaconda3
        -> scipy, matplotlip, pip
    changed backend keras to theano in /home/.keras/keras.json
    learned how to import csv
    plt.imshow(np.reshape(newdata[1],[28,28])), plt.show()
    Flatten() layer if outputs dont match labels
    train-test split
    0.958 accuracy 1 epoch (but 0.92 on training)
    the reshape is useless but lets me see the images

18-02-2020
    data: https://www.kaggle.com/c/digit-recognizer/data
    found mistake! for theano, keras.json->image_data_format is channels_first, while for tensorflow it should be channels_last! maybe that's why yesterday I was having problems? will test.  turns out, i did make a mistake but the problem wasn't due to that. fixed now
    0.974 accuracy 1 epoch
    learned convolution and pooling (pooling is kinda trash, but understand)
    correction: pooling is smart. whish there was a better way to generalize on traslation...
    started watching 6.S191

19-02-2020
    created git repo
    started reading http://karpathy.github.io/2015/05/21/rnn-effectiveness/
        doesnt explain LSTM. will find different source in future
        https://github.com/kjw0612/awesome-rnn
        uses lua/torch. will keep reading, but focus on keras for one more model, then tensorflow, then maybe pytorch
        truncated backprop:     "Truncated backpropagation is arguably the most practical method for training RNNs.… One of the main problems of BPTT is the high cost of a single parameter update, which makes it impossible to use a large number of iterations.…The cost can be reduced with a naive method that splits the 1,000-long sequence into 50 sequences (say) each of length 20 and treats each sequence of length 20 as a separate training case. This is a sensible approach that can work well in practice, but it is blind to temporal dependencies that span more than 20 timesteps.…    Truncated BPTT is a closely related method. It processes the sequence one timestep at a time, and every k1 timesteps, it runs BPTT for k2 timesteps, so a parameter update can be cheap if k2 is small. Consequently, its hidden states have been exposed to many timesteps and so may contain useful information about the far past, which would be opportunistically exploited." from http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf  may be useful again in future.
    Read about capsule neural networks
        https://arxiv.org/abs/1710.09829 main paper
        https://github.com/naturomics/CapsNet-Tensorflow tensorflow implementation
        basic gist: a capsule is a group of neurons, and it produces an activity vector. its length is the probability the entity it represents exists, and its orientation represents the instantiation parameters (this is supposedly a better way to generalize on trasformations than pooling). When many capsules agree on existence, higher level capsule becomes active, but a lower level sends to a higher level with highest scalar product between prediction (from lower level) and activity vector (higher level). doesnt this correlate stuff? This is too complex, no point wasting too much time. may come back in the future.
    http://colah.github.io/posts/2015-08-Understanding-LSTMs/ LSTM theory. very clear and simple
    fixed dates. apparently i got the date wrong TWO days in a row...
    while putting together LSTM model found out Keras with Theano cannot set dropout in LSTM layers. will now switch to tensorflow
    
tmrw:
    sequential data and recurrent networks
    LSTM
    lstm in computer vision (?)
    generative networks
    meaning of epochs
    visualizing accuracy evolution
    implementing normal and recurrent networks manually
    attention/augmented RNNs https://distill.pub/2016/augmented-rnns/
    reinforcement learning
    scikit-learn (?)
    
20-02-2020
    let's start looking at tensorflow. will re-do the three projects completed so far, in tf
    tf.keras == keras with tf. will skip this?
    i'll start by running tensorflow on Docker to use GPU

21-02-2020
    apparently wasn't as easy as i thought. done now. changed video drivers, used precompiled binaries from AUR, CUDA 10.1 is the one i can use (correction: changed driver series, should check on CUDA website) (but dont, as docker does not need cuda installed in host system), will save a couple useful commands

22-02-2020
    - docker run --name tftrial --gpus all -it -v ~/Documents/studies/intro/:/tmp -w /tmp --rm tensorflow/tensorflow:latest-gpu bash 
    this opens a new container with name tftrial, with gpu "privileges", mounts directory ~/D/s/i, changes working directory of container to /tmp, with the tensorflow-gpu image and opens bash. to get out, Ctrl+p - Ctrl+q will now turn interactive mode into daemon mode (if:
    was a TTY allocated (-t)
    was stdin left open (-i).)
    ofc, just because docker is the simpler option, it does not mean it is simple. read http://phusion.github.io/baseimage-docker/#intro for interesting info. i will keep using docker exec, as tensorflow wiki [https://www.tensorflow.org/install/docker] proposes it, altough [https://github.com/phusion/baseimage-docker#login_docker_exec].
    - can avoid docker exec problems by running processes from inside bash: this way (i think) what i run is child of bash, and bash reaps it (pretty sure) but not sure if killing bash kills process. shouldnt need to know anyway.
    this took forever. ill skim over tf.keras (there doesnt seem to be anything new) and next will be custom tensorflow.
    
23-02-2020
    didn't write much, read a few articles, as [https://www.pyimagesearch.com/2018/10/08/keras-vs-tensorflow-which-one-is-better-and-which-one-should-i-learn/], maybe will get his book (got it, will try to skim in following days)
    
24-02-2020
    little time. cleaned up a bit, got a couple books, realized that machine learning is divided in supervised/unsupervised/reinforcement. Now, very interested in reinforcement, but i think i should complete others first. so, in the next few days:
    
    tensorflow "bare bones"
    possibly manual implementation of something
    re-study other data science techniques, maybe use R datasets
    really wanna learn twitter sent analysis
    a couple unsupervised techniques
    reinforcement learning (really want to know what it's all about)

26-02-2020
    will go through other keras examples. Now i understand the power of using a high level API mixed with "lower" level Tensorflow for specific things (still have to see what those will be). PyTorch will be tough.
    following https://keras.io/examples/addition_rnn/ faithfully to understand
    I'm a little bit stumped on the RepeatVector. read this [https://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/], but still not sure. i think im missing some info on RNN in general. from the article, when exploring MLPs instead of recurrent, "The issue is that we encoded so much of the domain into the problem that it turned the problem from a sequence prediction problem into a function mapping problem. That is, the order of the input no longer matters. We could shuffle it up any way we want and still learn the problem. MLPs are designed to learn mapping functions and can easily nail the problem of learning how to add numbers. On one hand, this is a better way to approach the specific problem of adding numbers because the model is simpler and the results are better. On the other, it is a terrible use of recurrent neural networks."
    Read a bit more on encoder-decoder. i think i should hit pause on the implementation and get further with theory, but not sure yet.
    "First, the input sequence is shown to the network one encoded character at a time. We need an encoding level to learn the relationship between the steps in the input sequence and develop an internal representation of these relationships. One or more LSTM layers can be used to implement the encoder model. The output of this model is a fixed-size vector that represents the internal representation of the input sequence. The number of memory cells in this layer defines the length of this fixed-sized vector.[...] As with the Vanilla LSTM, a Dense layer is used as the output for the network. The same weights can be used to output each time step in the output sequence by wrapping the Dense layer in a TimeDistributed wrapper."

27-02-2020
    completed yesterday's model, helped a friend learn.

12-04-2020
    been a while. wrote a complete model for fake news detection, with GloVe embedding, LSTM-CNN, and a beautiful misuse of Python to create java-looking implementation of a "full" handler class for the model. may update it in the future, just felt like it was time. actually spent a ton of time on this, about 12 hours total. had fun and learnt a lot! still, incomplete.
    MAIN sources:
        https://gist.github.com/JacopoMangiavacchi/7d6a8310e73af8f8f902f8dfa6204b04#file-createmodelwithgloveembedding-ipynb
        https://github.com/pmsosa/CS291K/blob/925f38bb5a9a802cfc60f8cc439cb9f2548854af/lstm_cnn.py#L5
    i HAVE to switch from full scripts to notebooks, it's getting silly. also, i forgot how to use docker to use gpu. not that it matters that much. next time ill set up gpu for normal python calls

20-04-2020
    the handler class was revamped multiple times. turns out, i'd made a mistake! fixed now, and with better methods
